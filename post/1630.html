<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <meta name="author" content="Craig Gidney">
    <meta name="keywords" content="computer science,algorithms,quantum computing,blog">
    <meta name="description" content="Craig Gidney's computer science blog">
    <title>Improper Priors</title>
    <link rel="shortcut icon" href="/assets/favicon.ico">
    <meta name="viewport" content="width=device-width">

    <!-- syntax highlighting CSS -->
    <link rel="stylesheet" href="/css/syntax.css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/main.css">

    <!-- RSS autodiscovery -->
    <link rel="alternate" type="application/rss+xml" title="RSS" href="/feed.xml">
  </head>
  <body>
    <div class="header">
      <a href="/"><img src="/assets/banner.png" alt="Algorithmic Assertions - Craig Gidney's Computer Science Blog" id="site_banner"/></a>
    </div>
    <div class="site">

      <h1 class="post_title">Improper Priors</h1>
<p class="meta">04 Dec 2016</p>

    <!-- MathJax latest -->
    <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [['$','$']],
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        TeX: {
          Macros: {
            ket: ["\\left|{#1}\\right\\rangle", 1],
            bra: ["\\left\\langle{#1}\\right|", 1],
            parens: ["\\left({#1}\\right)", 1],
            bracket: ["\\left[{#1}\\right]", 1],
            brace: ["\\left\\{ {#1} \\right\\}", 1],
            Sum: ["\\underset{#1}{\\overset{#2}{\\Sigma}}", 2],
            bimat: ["\\begin{bmatrix} {#1} & {#2} \\\\ {#3} & {#4} \\end{bmatrix}", 4]
          }
        }
      });
    </script>
    <noscript>
      <font color=red>
        MathJax was blocked.
        Formulas like <strong>$\frac{a}{b}$</strong> won't render into <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAYCAIAAACjjJBEAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAFnSURBVDhPY/hPCCBU/P1wamJqZFpBTnJcqLl9142fUHGYip93Znopuc55+Pv/zyv16kJ+W99DJaAq/r3bGiLA67cFJPxuo5eI8bSHf8ASQABR8e1krhSr+ZwnQOGvx9LlFPNPvnv37vs/sBxExc/rrToy8Ye+/P/7ekeKFK/H2guLsvuvQlwCdcefF1sKPX3ic8qaJkzKsTcPSKzY8PQ3RArmUtyAWioYcAOoCvyAyiq+nusIVGdl0O6+/QsqAgYoZnw5nCSlkHfqG5QLAcgqflyuVZeI3PMJyoUCJBV/Hk43YRFySSvIDHXyrNr75i9EGKHi35t1HvxKxUc+/vv/cYe/qNGEu5CIQaj4cjBBSrn03HewYUZsStWXfoDF4Sp+351gKB688yMwOb5c4cwlmngA6h64ir9P59lr5Jz89v/nrQnWsl4LH0MjH8mWvx9OdEUFJ6TEhGXPu/IFkr5AAKECO/j/HwCRTZMPA+AaqQAAAABJRU5ErkJggg==" />.
      </font>
      <br>
      Allow scripts from <strong>algorithmicassertions.com</strong> and <strong>mathjax.org</strong> to fix.
      <hr/>
    </noscript>

<div class="post">
<p>Here is the basic process for Bayesian reasoning:</p>

<ol>
<li><p>Start with a <a href="https://en.wikipedia.org/wiki/Prior_probability">prior</a>. A probability distribution over hypothesis space that represents your starting beliefs.</p></li>
<li><p>Make an observation $B$.</p></li>
<li><p>Scale the prior pointwise by each hypothesis&#39; predicted probability of $B$.</p></li>
<li><p>Normalize the prior so it adds up to 100%. This is your new <a href="https://en.wikipedia.org/wiki/Posterior_probability">posterior</a>.</p></li>
<li><p>Goto <strong>2</strong>.</p></li>
</ol>

<p>One of the problems you run into right away, when implementing this in a computer program, is &quot;How do I pick the prior?&quot;.
A good rule of thumb is to just assign each hypothesis equal likelihood, but this breaks down in cases where there are infinitely many possible hypotheses.
The probabilities-must-add-up-to-100% requirement forces you to compute $\infty/\infty$, which is undefined, and all the math gears seize up.</p>

<p>There are many reasonable workarounds for this problem, but I want to discuss one that I came up with: just saying &quot;screw normalization!&quot;.
(Actually, as per usual, I quickly found out my idea was in no way original.
<a href="https://en.wikipedia.org/wiki/Prior_probability#Improper_priors">Improper priors are a century-old tool</a> that I should have known about before starting this post...
but here we are regardless.)</p>

<p>Suppose, for the sake of argument, that we started the Bayesian inference process with a distribution that wasn&#39;t a probability distribution.
What happens?
Let&#39;s do an example to see.</p>

<p>Suppose we are sampling from a normal distribution.
We know that the mean of the distribution is $\mu=0$, but we don&#39;t know the standard deviation $\sigma$.
We want to use Bayesian reasoning to infer $\sigma$, so we need a prior.
We decide to use the improper uniform prior $P_0(\sigma) = 1$ for $\sigma \in (0, \infty)$:</p>

<p><img style="max-width:100%;" src="/assets/2016-12-04-malformed-priors/stdev-prior.png"/></p>

<p>Now we do an inference step.
We sample $x_1$ from the distribution, and find that $x_1=6$.</p>

<p>Given a hypothesized $\sigma$, the probability of sampling $x_1=6$ is $\mathcal{N}_{0, \sigma}(6)$.
That means our posterior is:</p>

<p>$$\begin{align}
P_1(\sigma)
&amp;\propto P_0(\sigma) \cdot \mathcal{N}_{0, \sigma}(6)
\\
&amp;= 1 \cdot \frac{\exp\left( -6^2 / 2 \sigma^2 \right)}{\sigma \sqrt{\tau}}
\\
&amp;= \frac{\exp\left( -18 / \sigma^2 \right)}{\sigma \sqrt{\tau}}
\end{align}$$</p>

<p><img style="max-width:100%;" src="/assets/2016-12-04-malformed-priors/stdev-posterior-1.png"/></p>

<p>Note that we didn&#39;t normalize.
That&#39;s because we can&#39;t.
This is still a malformed distribution.
The numerator of $P_1$ converges to 1, but the denominator makes the expression act like $1/\sigma$.
So the overall the cumulative distribution will diverge like $\Theta(\lg \sigma)$.</p>

<p>Things are still broken after one observation, but they&#39;re not <em>as</em> broken.
We used to be diverging linearly, but now we&#39;re only diverging logarithmically.
Maybe another sample will do the trick?</p>

<p>We sample again, find that $x_2=42$, and compute the posterior:</p>

<p>$$\begin{align}
P_2(\sigma)
&amp;\propto P_1(\sigma) \cdot \mathcal{N}_{0, \sigma}(42)
\\
&amp;= \frac{\exp\left( -18 / \sigma^2 \right)}{\sigma \sqrt{\tau}} \cdot \frac{\exp\left( -42^2 / 2 \sigma^2 \right)}{\sigma \sqrt{\tau}}
\\
&amp;= \frac{\exp\left( -18 / \sigma^2 \right)}{\sigma \sqrt{\tau}} \cdot \frac{\exp\left( -882/ \sigma^2 \right)}{\sigma \sqrt{\tau}}
\\
&amp;= \frac{\exp\left( -30^2/ \sigma^2 \right)}{\sigma^2 \tau}
\end{align}$$</p>

<p>Now that the denominator is squared, the cumulative distribution converges to a finite number:</p>

<p>$$\int_0^\infty \frac{\exp\left(-30^2/ \sigma^2 \right)}{\sigma^2 \tau} d\sigma = \frac{1}{120 \sqrt{\pi}} \approx 0.0047$$</p>

<p>And we can get a proper posterior <em>probability</em> distribution by using this cumulative total to renormalize:</p>

<p>$$
P_2(\sigma) =\frac{60 \exp\left(-30^2/ \sigma^2 \right)}{\sigma^2 \sqrt{\pi}}
$$</p>

<p><img style="max-width:100%;" src="/assets/2016-12-04-malformed-priors/stdev-posterior-2.png"/></p>

<p>Although we started with a meaningless prior, the updating process eventually brought us back into the space of well-formed probability distributions.
This is kind of nice, because $P(x) = 1$ is a very simple prior.
It doesn&#39;t even take any parameters!
Sure it forces some minimum number of observations before you&#39;re able to get a meaningful prediction, but it&#39;s not like other uninformed priors were going to score well on metrics before being updated by observations.</p>

<p>In fact, I think this concept of improper prior justifies a lot of frequentist statistics.
A good example is what happens when you estimate the true mean of a population by sampling.
A frequentist calculation creates a distribution of possible means exactly centered on the sampled mean.
But a hard-core literal Bayesian would start with a prior, and that prior would bias the posterior away from being centered exactly on the sampled mean... <em>unless you started with the improper prior $\forall \mu, P(\mu) = 1$</em>.</p>

<p>Do be careful, though.
You can create some pretty crazy improper priors.
For example, consider $P(x) = e^{x^2}$ for $x \in (-\infty, +\infty)$.
A Bayesian computer program initialized with such a prior would have what I can only describe as an unbreakable faith in the infinite.
No matter how many normally-distributed observations you fed in, you&#39;d never get a proper probability distribution out.</p>

<p>In addition to the prior being too wild, the updating process may be too weak or the hypothesis space may be too complicated.
For example, even a nearly-converging prior like $P(x) = 1/x$ will cause serious problems for <a href="https://en.wikipedia.org/wiki/Solomonoff&#x27;s_theory_of_inductive_inference">Solomonoff induction</a>.</p>

<h1>Summary</h1>

<p>By definition, Bayesian priors are probability distributions.
But violating that definition leads to interesting and useful behaviors.</p>

</div>


    </div>

    <div class="footer-container">
      <div class="site">
        <div class="footer">
          <div class="contact">
            by: Craig Gidney<br />
            more: <a href="/">All Posts</a>, <a href="/feed.xml">Posts Feed<img src="/assets/feed-icon.png" width="16px" alt="Posts Feed" title="Posts Feed" /></a><br/>
            meta: <a href="/about.html">About the Author/Blog</a><br/>
          </div>
          <div class="license">
            <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">
              <img alt="Creative Commons License" style="border-width:0" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAFgAAAAfCAYAAABjyArgAAAFOklEQVRo3u1aTU8bRxj2OVIs7lw4hhttlR5TpPQHkB+QiH9Q1FskqqCIVIpUCVmuoubQUKm3JrDG5sNfeA1rY3vX9noh5MpP4Ce81fOu32V2WfAHzhoTRhqx3pmdHZ595nk/ZmJEFI/FYnRfR1+J8Kf7Yye/TXvFXcqVslQ8KFDJKNFBtUxG3aAjs0r1Zo0arQZZbZOatkXNTtOttkWWbZLZanAf9K3UDX5WN0o8Vq6U47Hxjkw2TVt7KUrtaLS5vUEbmU9cP6U/0set/+5MVYC+ADev52j/sEjlik5G7ZDBarTqDGDbaVHnxCbnc4eOT4/p5Itbce18drgNfSzb4mfwLMYoV3UeE2MHQdZ2Nj2QAfAdBTnmB7daZgbWrBqzFaAB1NU3q/T056f0MP7w0lLAPbSt/r7KfdvHbf4oYHSlUWE27x/u+0BOZ7cotau5IGc2Rsbil8svaXZ29tIccQ9tYwEYsqCCC2CaHYtZmUgmaHp6um/dQd/Enwl+FhICNlc9kIueXGznMpTec0EeBYuTfyXp0ewjbx7z8/O0tLTEFddyH33QN1KAoZOQhQtwm8zEhWcLPvCmpqZocXGRVlZWSNd1rrjGPbSpffFspWZQy3FBBpMhF64mZ2m3sOOXihuweP3fDxSPx933LizQ2dkZBQvuoQ190DcKkD2AYdCgl5AFMDcILsADkOfn53RdWV9f9wENtgBkfDB8OLwDhq9QzlN2f8+VihAWD/qPCHPxodWiWHPfHGVukQGM5QujBM3F0lbBnZubC2XEVQUfAc+oTMaY0GS840IqFBbvpkjb3hxKJqCrwtwvp6c9AUYRJn9tTfYANlga6mzQoLkquL1Y2w/I0GQYPpaKukF6xWUxa3He1WKRiUEBFoM2CAnQVwxfJAAze22TpUEMGpa6bds0bAHIIhcYE2PDhRMWFw9cFqsexTAyIQYtWCAX8oGD0oEihi8SgKGPLafFrphMCpp70yJ6hwoXDitEtLjUddtUmRgWYHgKwRISVfkKnokMYERo9onNvqywV5UGeAvQLXx1VBX8YNva2prvHxEWY2xoMSK+SzKRy7jehKLDdwpgGDcsYQki1CUFAMP8XYCpaVpom/q8LFWMjYgPUlTtumyFcoG9CeiwuGt3UiKQTzg+dbwJqSwUYzUzM8PGAYDjGstf2sTTAODSFiYTCKubPh0u+Ny1YQC+zshdxd7IjRx8X+QVZEIAMTjJME3uR6/VFYB3wCc+Mo9GBrDqpvULcORu2iQDPGigIdobaaDRr0TA8MF1wzVAVSUi2BaVRExEqHydkbvOkPVj5IQxrpHr8LtGaeRUkNVkDz465oH3q0HPWJI94qZJiAzXKrjMr3LTALLcD7ahgNGqm9ZQ3LS8fnM3bSLSlRJoqGFy0J8dZaBx2A00kLqUQOOmCZ9bnXCvNsJD5UHi+3GFyhMBsJrs+fDP36NP9iQTPDaSPXiXpCzVxPuwyZ6JABh1+dWyl658/uK5D+RBkj5gfWi6sm3S6zevv8Xd5YsfS7/+wm5UZ4iEO9rQR024P/7xMUsD/Gx8wG90+95/47dXyxwMAGSVycNsGQHcVqdJ796/i+ocQmiQEewzVoA9kG130xOaPPCmZ1I2Pa3IwA2CF3Y9BnDDARa5ULftAVqvbXvsXPC2Pc5HtM3IZaFXuvJWSIRav//hO9LSGrtw8JNt7+CJoxw8cfieevAkldHoyU9PxnFU6TZJQ2+ApQKst3+8pWK5qByd6lYcnWqb3IY+4wB2Yhl8X0dQiejBPRBf73Tl/8YjNDN/aKmsAAAAAElFTkSuQmCC" />
            </a><br />
            This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.
          </div>
        </div>
      </div>
    </div>
  </body>
</html>
